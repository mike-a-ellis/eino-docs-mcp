---
phase: 02-document-processing
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/metadata/generator.go
autonomous: true
user_setup:
  - service: openai
    why: "LLM metadata generation using GPT-4o"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Platform -> API keys (https://platform.openai.com/api-keys)"
    dashboard_config: []

must_haves:
  truths:
    - "Generator produces concise summaries capturing document topic and key points"
    - "Generator extracts EINO-specific entities (functions, interfaces, types)"
    - "Generator handles large documents via truncation"
  artifacts:
    - path: "internal/metadata/generator.go"
      provides: "LLM-based metadata generation"
      exports: ["Generator", "NewGenerator", "GenerateMetadata", "DocumentMetadata"]
  key_links:
    - from: "internal/metadata/generator.go"
      to: "openai/openai-go"
      via: "Chat completions API"
      pattern: "client\\.Chat\\.Completions\\.New"
---

<objective>
Implement LLM metadata generator for document summaries and entity extraction

Purpose: Generate per-document metadata using GPT-4o for rich summaries and EINO-specific entity extraction. Per-document generation (not per-chunk) reduces costs by 10-20x.

Output: Generator that produces summaries and entity lists for each document.
</objective>

<execution_context>
@/home/bull/.claude/get-shit-done/workflows/execute-plan.md
@/home/bull/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-document-processing/02-RESEARCH.md
@.planning/phases/02-document-processing/02-CONTEXT.md
@internal/storage/models.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement metadata generator</name>
  <files>internal/metadata/generator.go</files>
  <action>
Create LLM-based metadata generator using GPT-4o:

1. Uses existing openai-go dependency (no new deps needed)

2. Define DocumentMetadata struct:
   ```go
   type DocumentMetadata struct {
       Summary  string   `json:"summary"`
       Entities []string `json:"entities"`
   }
   ```

3. Define Generator struct:
   - Stores *openai.Client
   - Stores max tokens for truncation (default 16000)

4. NewGenerator function:
   - Takes openai.Client (reuse from embedding package)
   - Optional max tokens parameter
   - Returns configured Generator

5. GenerateMetadata method:
   - Input: document path (for context), content string
   - Output: *DocumentMetadata, error

   Implementation:
   ```go
   func (g *Generator) GenerateMetadata(ctx context.Context, path, content string) (*DocumentMetadata, error) {
       // Truncate if too long
       truncated := g.truncateContent(content)

       prompt := fmt.Sprintf(`Analyze this EINO framework documentation and provide:
1. A concise summary (1-2 sentences) capturing the main topic and key points
2. A list of key EINO functions, interfaces, classes, or types mentioned

Document path: %s

Document content:
%s

Respond in JSON format:
{"summary": "Brief description of what this document covers", "entities": ["Entity1", "Entity2"]}

Focus on EINO-specific concepts like:
- Components: ChatModel, Retriever, Embedding, Tool, Callback
- Interfaces: their methods and purposes
- Configuration: options, parameters, settings
- Patterns: chains, agents, flows`, path, truncated)

       resp, err := g.client.Chat.Completions.New(ctx, openai.ChatCompletionNewParams{
           Messages: openai.F([]openai.ChatCompletionMessageParamUnion{
               openai.UserMessage(prompt),
           }),
           Model: openai.F(openai.ChatModelGPT4o),
           ResponseFormat: openai.F[openai.ChatCompletionNewParamsResponseFormatUnion](
               openai.ResponseFormatJSONObjectParam{
                   Type: openai.F(openai.ResponseFormatJSONObjectTypeJSONObject),
               },
           ),
       })
       if err != nil {
           return nil, fmt.Errorf("chat completion failed: %w", err)
       }

       var metadata DocumentMetadata
       if err := json.Unmarshal([]byte(resp.Choices[0].Message.Content), &metadata); err != nil {
           return nil, fmt.Errorf("failed to parse response: %w", err)
       }

       return &metadata, nil
   }
   ```

6. truncateContent helper:
   - If content > maxTokens * 4 chars (rough token estimate), truncate
   - Take first portion of content
   - Log warning when truncation occurs
   - Decision (from CONTEXT.md): Truncate to first 16k tokens

7. Error handling:
   - No retry for metadata generation (unlike embeddings)
   - Errors should propagate up to indexer for logging
   - Do NOT fail entire batch on single document metadata failure

Constants:
- DefaultMaxTokens = 16000
- Model = openai.ChatModelGPT4o
  </action>
  <verify>
go build ./internal/metadata/...
  </verify>
  <done>
Generator produces summaries and entities via GPT-4o; compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit test for JSON parsing</name>
  <files>internal/metadata/generator_test.go</files>
  <action>
Create unit tests for metadata parsing (not API calls):

1. TestParseMetadataResponse:
   - Verify JSON parsing of valid response
   - Input: `{"summary": "Test summary", "entities": ["Entity1", "Entity2"]}`
   - Verify: Summary and Entities correctly populated

2. TestTruncateContent:
   - Verify truncation works correctly
   - Input: Very long string (100k chars)
   - Verify: Output is within expected bounds

3. TestTruncateContent_Short:
   - Verify short content not truncated
   - Input: Short string (1000 chars)
   - Verify: Output equals input

Note: These test the parsing logic, not the OpenAI API (which would require mocking or integration tests).
  </action>
  <verify>
go test -v ./internal/metadata/...
  </verify>
  <done>
Unit tests pass for metadata parsing and truncation logic
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `go build ./...` succeeds
2. `go test ./internal/metadata/...` passes
3. Generator produces DocumentMetadata with Summary and Entities
4. Large content is properly truncated
</verification>

<success_criteria>
- Generator calls GPT-4o with JSON response format
- Summary captures document topic and key points
- Entities list EINO-specific functions/interfaces/types
- Large documents are truncated to prevent token limit errors
- All code compiles and tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-document-processing/02-04-SUMMARY.md`
</output>
